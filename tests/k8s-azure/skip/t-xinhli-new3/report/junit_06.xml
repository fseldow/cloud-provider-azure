<?xml version="1.0" encoding="UTF-8"?>
  <testsuite tests="7" failures="1" time="318.286310435">
      <testcase name="[sig-storage] Subpath [Volume type: gluster] should support existing directories when readOnly specified in the volumeSource" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] Subpath [Volume type: gcePDPVC] should support restarting containers using file as subpath [Slow]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [NodeFeature:FSGroup]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] [sig-node] kubelet [k8s.io] [sig-node] Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s." classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-apps] Network Partition [Disruptive] [Slow] [k8s.io] [Job] should create new pods when node is partitioned" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]" classname="Kubernetes e2e suite" time="70.394707181"></testcase>
      <testcase name="[sig-storage] PersistentVolumes-local  [Volume type: dir-bindmounted] Set fsGroup for local volume should set different fsGroup for second pod if first pod is deleted" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-network] Services should have session affinity work for LoadBalancer service with ESIPP on [Slow] [DisabledForLargeClusters]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] GKE node pools [Feature:GKENodePool] should create a cluster with multiple node pools [Feature:GKENodePool]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] HostPath should give a volume the correct mode [NodeConformance] [Conformance]" classname="Kubernetes e2e suite" time="10.363860595"></testcase>
      <testcase name="[sig-network] Loadbalancing: L7 Scalability GCE [Slow] [Serial] [Feature:IngressScale] Creating and updating ingresses should happen promptly with small/medium/large amount of ingresses" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-autoscaling] [HPA] Horizontal pod autoscaling (scale resource: Custom Metrics from Stackdriver) should scale down with Custom Metric of type Pod from Stackdriver with Prometheus [Feature:CustomMetricsAutoscaling]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] Subpath [Volume type: nfsPVC] should support restarting containers using directory as subpath [Slow]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-apps] Deployment deployment should support rollback" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] [Feature:Example] [k8s.io] RethinkDB should create and stop rethinkdb servers" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] PersistentVolumes-local  [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-autoscaling] Cluster size autoscaling [Slow] should correctly scale down after a node is not needed and one node is broken [Feature:ClusterSizeAutoscalingScaleDown]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] Subpath [Volume type: gcePDPartitioned] should support readOnly directory specified in the volumeMount" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] HostPath should support existing single file subPath" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-cluster-lifecycle] Addon update should propagate add-on file changes [Slow]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-scheduling] SchedulerPreemption [Serial] [Feature:PodPreemption] validates basic preemption works" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-network] Services should be able to switch session affinity for LoadBalancer service with ESIPP on [Slow] [DisabledForLargeClusters]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] PersistentVolumes GCEPD should test that deleting a PVC before the pod does not cause pod deletion to fail on PD detach" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]" classname="Kubernetes e2e suite" time="69.598073573">
          <failure type="Failure">/home/t-xinhli/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc420496320&gt;: {&#xA;        s: &#34;Namespace e2e-tests-container-probe-lfdtw is active&#34;,&#xA;    }&#xA;    Namespace e2e-tests-container-probe-lfdtw is active&#xA;not to have occurred&#xA;/home/t-xinhli/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:88</failure>
          <system-out>[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]&#xA;  /home/t-xinhli/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;Jun 13 03:16:40.499: INFO: &gt;&gt;&gt; kubeConfig: /home/t-xinhli/new-provider/cloud-provider-azure/t-xinhli-new3/kubeconfig&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;�[1mSTEP�[0m: Waiting for a default service account to be provisioned in namespace&#xA;[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]&#xA;  /home/t-xinhli/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79&#xA;Jun 13 03:16:40.593: INFO: Waiting up to 1m0s for all nodes to be ready&#xA;Jun 13 03:17:40.652: INFO: Waiting for terminating namespaces to be deleted...&#xA;Jun 13 03:17:40.657: INFO: Unexpected error occurred: Namespace e2e-tests-container-probe-lfdtw is active&#xA;[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]&#xA;  /home/t-xinhli/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-sched-pred-rsl86&#34;.&#xA;�[1mSTEP�[0m: Found 0 events.&#xA;Jun 13 03:17:40.695: INFO: POD                                                                    NODE                       PHASE      GRACE  CONDITIONS&#xA;Jun 13 03:17:40.695: INFO: liveness-http                                                          k8s-agentpool1-31296431-1  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:08 +0000 UTC  }]&#xA;Jun 13 03:17:40.695: INFO: liveness-exec                                                          k8s-agentpool1-31296431-1  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:15:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:15:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:15:41 +0000 UTC  }]&#xA;Jun 13 03:17:40.695: INFO: daemon-set-dzpks                                                       k8s-agentpool1-31296431-0  Pending    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:36 +0000 UTC ContainersNotReady containers with unready status: [app]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:24 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: pod-525e7744-6eb8-11e8-b08b-000d3a184d46                               k8s-agentpool1-31296431-1  Pending           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:37 +0000 UTC ContainersNotReady containers with unready status: [test-container]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:36 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: pod-517bfe9d-6eb8-11e8-9d88-000d3a184d46                               k8s-agentpool1-31296431-1  Pending           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:35 +0000 UTC ContainersNotReady containers with unready status: [test-container]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:35 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: simpletest.deployment-7557dbb5dc-7t47p                                 k8s-agentpool1-31296431-1  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:30 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: simpletest.deployment-7557dbb5dc-snmdw                                 k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:31 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: host-test-container-pod                                                k8s-agentpool1-31296431-1  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:24 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: netserver-0                                                            k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:54 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: netserver-1                                                            k8s-agentpool1-31296431-1  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:54 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: test-container-pod                                                     k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:24 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: pod-update-activedeadlineseconds-52912219-6eb8-11e8-a315-000d3a184d46  k8s-agentpool1-31296431-1  Pending           [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:37 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: server                                                                 k8s-agentpool1-31296431-1  Pending           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:33 +0000 UTC ContainersNotReady containers with unready status: [server]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:32 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: pod-projected-secrets-529ab591-6eb8-11e8-a995-000d3a184d46             k8s-agentpool1-31296431-0  Succeeded         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:37 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:37 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:37 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: proxy-service-kkkkg-xlmm2                                              k8s-agentpool1-31296431-1  Pending           [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:37 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: ss2-0                                                                  k8s-agentpool1-31296431-1  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:08 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: ss2-1                                                                  k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:47 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: ss2-2                                                                  k8s-agentpool1-31296431-1  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:16:20 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: svc-latency-rc-bj5ls                                                   k8s-agentpool1-31296431-1  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:09 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: pod-service-account-49f93ea9-6eb8-11e8-b5c9-000d3a184d46-9qkvz         k8s-agentpool1-31296431-1  Pending           [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 03:17:37 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: cloud-controller-manager-k8s-master-31296431-0                         k8s-master-31296431-0      Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: heapster-6f7b9bdf-52ntm                                                k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:58:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:42 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kube-addon-manager-k8s-master-31296431-0                               k8s-master-31296431-0      Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kube-apiserver-k8s-master-31296431-0                                   k8s-master-31296431-0      Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kube-controller-manager-k8s-master-31296431-0                          k8s-master-31296431-0      Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kube-dns-v20-59b4f7dc55-67fbv                                          k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:58:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:41 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kube-dns-v20-59b4f7dc55-phwv9                                          k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:58:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:41 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kube-proxy-5976x                                                       k8s-master-31296431-0      Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:26 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kube-proxy-89kmg                                                       k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:26 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kube-proxy-fr77g                                                       k8s-agentpool1-31296431-1  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:26 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kube-scheduler-k8s-master-31296431-0                                   k8s-master-31296431-0      Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:56:50 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: kubernetes-dashboard-65c8bbc84b-tf6lc                                  k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:42 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: metrics-server-5c74cf6d4f-h5mgt                                        k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:40 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: tiller-deploy-d85ccb55c-pk2j4                                          k8s-agentpool1-31296431-0  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:58:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-13 02:57:42 +0000 UTC  }]&#xA;Jun 13 03:17:40.696: INFO: &#xA;Jun 13 03:17:40.717: INFO: &#xA;Logging node info for node k8s-agentpool1-31296431-0&#xA;Jun 13 03:17:40.730: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:k8s-agentpool1-31296431-0,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/k8s-agentpool1-31296431-0,UID:74eaa19b-6eb5-11e8-9654-000d3a134c0e,ResourceVersion:7333,Generation:0,CreationTimestamp:2018-06-13 02:57:06 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{agentpool: agentpool1,beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: Standard_F2,beta.kubernetes.io/os: linux,daemonset-color: green,failure-domain.beta.kubernetes.io/region: eastus,failure-domain.beta.kubernetes.io/zone: 0,kubernetes.azure.com/cluster: t-xinhli-new3,kubernetes.io/hostname: k8s-agentpool1-31296431-0,kubernetes.io/role: agent,storageprofile: managed,storagetier: Standard_LRS,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:10.244.1.0/24,DoNotUse_ExternalID:,ProviderID:azure:///subscriptions/c4528d9e-c99a-48bb-b12d-fde2176a43b8/resourceGroups/t-xinhli-new3/providers/Microsoft.Compute/virtualMachines/k8s-agentpool1-31296431-0,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{2 0} {&lt;nil&gt;} 2 DecimalSI},ephemeral-storage: {{31158935552 0} {&lt;nil&gt;}  BinarySI},hugepages-1Gi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},hugepages-2Mi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},memory: {{4114132992 0} {&lt;nil&gt;} 4017708Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{2 0} {&lt;nil&gt;} 2 DecimalSI},ephemeral-storage: {{28043041951 0} {&lt;nil&gt;} 28043041951 DecimalSI},hugepages-1Gi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},hugepages-2Mi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},memory: {{4009275392 0} {&lt;nil&gt;} 3915308Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2018-06-13 02:58:57 +0000 UTC 2018-06-13 02:58:57 +0000 UTC RouteCreated RouteController created a route} {OutOfDisk False 2018-06-13 03:17:38 +0000 UTC 2018-06-13 02:57:05 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-06-13 03:17:38 +0000 UTC 2018-06-13 02:57:05 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-06-13 03:17:38 +0000 UTC 2018-06-13 02:57:05 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-06-13 03:17:38 +0000 UTC 2018-06-13 02:57:05 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-06-13 03:17:38 +0000 UTC 2018-06-13 02:57:36 +0000 UTC KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.240.0.5} {Hostname k8s-agentpool1-31296431-0}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:79fe54da919d45ff9e81f9bf6ebd36fb,SystemUUID:24B4B64B-ECDB-7144-A474-9331C73E23DF,BootID:3b74ef78-7064-4109-a243-e752fa302910,KernelVersion:4.13.0-1018-azure,OSImage:Ubuntu 16.04.4 LTS,ContainerRuntimeVersion:docker://1.13.1,KubeletVersion:v1.12.0-alpha.0,KubeProxyVersion:v1.12.0-alpha.0,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcrio.azureedge.net/google_containers/hyperkube-amd64@sha256:b92fc22f40fa4bf5d72ddd6e82ffd5d5a98ac9201eeb086843899f3a9fbf3eee gcrio.azureedge.net/google_containers/hyperkube-amd64:v1.12.0-alpha.0] 619581352} {[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils-amd64@sha256:b7fb726f862504ca6afcc512abf30456cbf4fbd6b4589af46d2c1d27cb89acf0 gcr.io/kubernetes-e2e-test-images/jessie-dnsutils-amd64:1.0] 189192551} {[k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b k8s.gcr.io/nginx-slim-amd64:0.20] 103591055} {[k8s-gcrio.azureedge.net/kubernetes-dashboard-amd64@sha256:dc4026c1b595435ef5527ca598e1e9c4343076926d7d62b365c44831395adbd0 k8s-gcrio.azureedge.net/kubernetes-dashboard-amd64:v1.8.3] 102319441} {[k8s.gcr.io/nginx-slim-amd64@sha256:8ca6a9ecef3b2ef02f6e0c3d449235d9c53d532f420cc0a29a6a133aa88df256 k8s.gcr.io/nginx-slim-amd64:0.21] 95339966} {[k8s-gcrio.azureedge.net/heapster-amd64@sha256:d4d10455d921802bdb004e7edfe423a2b2f88911319b48abf47e0af909f27f15 k8s-gcrio.azureedge.net/heapster-amd64:v1.5.1] 75318380} {[gcrio.azureedge.net/kubernetes-helm/tiller@sha256:394fb7d5f2fbaca54f6a0dec387cef926f6ae359786c89f7da67db173b97a322 gcrio.azureedge.net/kubernetes-helm/tiller:v2.8.1] 71509364} {[k8s-gcrio.azureedge.net/k8s-dns-kube-dns-amd64@sha256:6d8e0da4fb46e9ea2034a3f4cab0e095618a2ead78720c12e791342738e5f85d k8s-gcrio.azureedge.net/k8s-dns-kube-dns-amd64:1.14.8] 50456751} {[k8s-gcrio.azureedge.net/metrics-server-amd64@sha256:49a9f12f7067d11f42c803dbe61ed2c1299959ad85cb315b25ff7eef8e6b8892 k8s-gcrio.azureedge.net/metrics-server-amd64:v0.2.1] 42541759} {[k8s-gcrio.azureedge.net/k8s-dns-dnsmasq-nanny-amd64@sha256:93c827f018cf3322f1ff2aa80324a0306048b0a69bc274e423071fb0d2d29d8b k8s-gcrio.azureedge.net/k8s-dns-dnsmasq-nanny-amd64:1.14.8] 40951779} {[k8s-gcrio.azureedge.net/addon-resizer@sha256:507aa9845ecce1fdde4d61f530c802f4dc2974c700ce0db7730866e442db958d k8s-gcrio.azureedge.net/addon-resizer:1.8.1] 32968591} {[gcr.io/kubernetes-e2e-test-images/dnsutils-amd64@sha256:9e1873dbe19894688dc3d129994c952891d43794df2480217f899bf92732d35f gcr.io/kubernetes-e2e-test-images/dnsutils-amd64:1.0] 8871636} {[k8s-gcrio.azureedge.net/exechealthz-amd64@sha256:503e158c3f65ed7399f54010571c7c977ade7fe59010695f48d9650d83488c0a k8s-gcrio.azureedge.net/exechealthz-amd64:1.2] 8374840} {[gcr.io/kubernetes-e2e-test-images/netexec-amd64@sha256:2edfad424a541b9e024f26368d3a5b7dcc1d7cd27a4ee8c1d8c3f81d9209ab2e gcr.io/kubernetes-e2e-test-images/netexec-amd64:1.0] 6227659} {[gcr.io/kubernetes-e2e-test-images/redis-amd64@sha256:3e01bcaf67cb9b5c9fa7f57ba92539c8962d59c9647b91e9ec5047a89e2bc49a gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0] 5850779} {[gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64@sha256:2dd4032e98a0450d95a0ac71a5e465f542a900812d8c41bc6ca635aed1a5fc91 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0] 5470001} {[gcr.io/kubernetes-e2e-test-images/nautilus-amd64@sha256:a4e859e40750d0e1a94470445bea3bc0ba4edc7363863a0be7a3714336040daa gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0] 4415165} {[gcr.io/kubernetes-e2e-test-images/test-webserver-amd64@sha256:cd237408ae94e22c4f5c6d7c6f56708341db6c428180fe1fe011c17bf9d03c50 gcr.io/kubernetes-e2e-test-images/test-webserver-amd64:1.0] 4393904} {[gcr.io/kubernetes-e2e-test-images/mounttest-amd64@sha256:dc4e2dcfbde16249c4662de673295d00778577bc2e2ca7013a1b85d4f47398ca gcr.io/kubernetes-e2e-test-images/mounttest-amd64:1.0] 1450451} {[gcr.io/kubernetes-e2e-test-images/mounttest-user-amd64@sha256:dda6519a95c934b46731a6b1492fed1b48ccc6d4aed4b754a46d7de8063a3e2b gcr.io/kubernetes-e2e-test-images/mounttest-user-amd64:1.0] 1450451} {[busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47 busybox:latest] 1146369} {[k8s-gcrio.azureedge.net/pause-amd64@sha256:59eec8837a4d942cc19a52b8c09ea75121acc38114a2c68b98983ce9356b8610 k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s-gcrio.azureedge.net/pause-amd64:3.1 k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}&#xA;Jun 13 03:17:40.730: INFO: &#xA;Logging kubelet events for node k8s-agentpool1-31296431-0&#xA;Jun 13 03:17:40.753: INFO: &#xA;Logging pods the kubelet thinks is on node k8s-agentpool1-31296431-0&#xA;Jun 13 03:17:40.786: INFO: kube-dns-v20-59b4f7dc55-67fbv started at 2018-06-13 02:57:41 +0000 UTC (0+3 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container dnsmasq ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container healthz ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container kubedns ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: kubernetes-dashboard-65c8bbc84b-tf6lc started at 2018-06-13 02:57:42 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container kubernetes-dashboard ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: tiller-deploy-d85ccb55c-pk2j4 started at 2018-06-13 02:57:42 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container tiller ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: pod-projected-secrets-529ab591-6eb8-11e8-a995-000d3a184d46 started at 2018-06-13 03:17:37 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container projected-secret-volume-test ready: false, restart count 0&#xA;Jun 13 03:17:40.786: INFO: kube-proxy-89kmg started at 2018-06-13 02:57:26 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container kube-proxy ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: netserver-0 started at 2018-06-13 03:16:54 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container webserver ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: heapster-6f7b9bdf-52ntm started at 2018-06-13 02:57:42 +0000 UTC (0+2 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container heapster ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container heapster-nanny ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: daemon-set-dzpks started at 2018-06-13 03:17:24 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container app ready: false, restart count 0&#xA;Jun 13 03:17:40.786: INFO: kube-dns-v20-59b4f7dc55-phwv9 started at 2018-06-13 02:57:41 +0000 UTC (0+3 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container dnsmasq ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container healthz ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container kubedns ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: test-container-pod started at 2018-06-13 03:17:24 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container webserver ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: ss2-1 started at 2018-06-13 03:16:52 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container nginx ready: false, restart count 0&#xA;Jun 13 03:17:40.786: INFO: simpletest.deployment-7557dbb5dc-snmdw started at 2018-06-13 03:17:31 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container nginx ready: true, restart count 0&#xA;Jun 13 03:17:40.786: INFO: metrics-server-5c74cf6d4f-h5mgt started at 2018-06-13 02:57:41 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:40.786: INFO: &#x9;Container metrics-server ready: true, restart count 0&#xA;Jun 13 03:17:40.944: INFO: &#xA;Latency metrics for node k8s-agentpool1-31296431-0&#xA;Jun 13 03:17:40.944: INFO: {Operation: Method:pod_start_latency_microseconds Quantile:0.99 Latency:13.896573s}&#xA;Jun 13 03:17:40.944: INFO: {Operation:create Method:pod_worker_latency_microseconds Quantile:0.9 Latency:11.231301s}&#xA;Jun 13 03:17:40.944: INFO: {Operation:create Method:pod_worker_latency_microseconds Quantile:0.5 Latency:11.231301s}&#xA;Jun 13 03:17:40.944: INFO: {Operation:create Method:pod_worker_latency_microseconds Quantile:0.99 Latency:11.231301s}&#xA;Jun 13 03:17:40.944: INFO: &#xA;Logging node info for node k8s-agentpool1-31296431-1&#xA;Jun 13 03:17:40.992: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:k8s-agentpool1-31296431-1,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/k8s-agentpool1-31296431-1,UID:7879044f-6eb5-11e8-9654-000d3a134c0e,ResourceVersion:7199,Generation:0,CreationTimestamp:2018-06-13 02:57:12 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{agentpool: agentpool1,beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: Standard_F2,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: eastus,failure-domain.beta.kubernetes.io/zone: 1,kubernetes.azure.com/cluster: t-xinhli-new3,kubernetes.io/hostname: k8s-agentpool1-31296431-1,kubernetes.io/role: agent,storageprofile: managed,storagetier: Standard_LRS,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:10.244.2.0/24,DoNotUse_ExternalID:,ProviderID:azure:///subscriptions/c4528d9e-c99a-48bb-b12d-fde2176a43b8/resourceGroups/t-xinhli-new3/providers/Microsoft.Compute/virtualMachines/k8s-agentpool1-31296431-1,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{2 0} {&lt;nil&gt;} 2 DecimalSI},ephemeral-storage: {{31158935552 0} {&lt;nil&gt;}  BinarySI},hugepages-1Gi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},hugepages-2Mi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},memory: {{4114132992 0} {&lt;nil&gt;} 4017708Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{2 0} {&lt;nil&gt;} 2 DecimalSI},ephemeral-storage: {{28043041951 0} {&lt;nil&gt;} 28043041951 DecimalSI},hugepages-1Gi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},hugepages-2Mi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},memory: {{4009275392 0} {&lt;nil&gt;} 3915308Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2018-06-13 02:58:57 +0000 UTC 2018-06-13 02:58:57 +0000 UTC RouteCreated RouteController created a route} {OutOfDisk False 2018-06-13 03:17:34 +0000 UTC 2018-06-13 02:57:12 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-06-13 03:17:34 +0000 UTC 2018-06-13 02:57:12 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-06-13 03:17:34 +0000 UTC 2018-06-13 02:57:12 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-06-13 03:17:34 +0000 UTC 2018-06-13 02:57:12 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-06-13 03:17:34 +0000 UTC 2018-06-13 02:57:42 +0000 UTC KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.240.0.4} {Hostname k8s-agentpool1-31296431-1}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:61830f4d09b34235983a7fcd5f6f65d7,SystemUUID:08BFB559-3D6E-1842-B07C-D04E1987CF9D,BootID:0a8fe774-fb14-491c-9538-7f647358d372,KernelVersion:4.13.0-1018-azure,OSImage:Ubuntu 16.04.4 LTS,ContainerRuntimeVersion:docker://1.13.1,KubeletVersion:v1.12.0-alpha.0,KubeProxyVersion:v1.12.0-alpha.0,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcrio.azureedge.net/google_containers/hyperkube-amd64@sha256:b92fc22f40fa4bf5d72ddd6e82ffd5d5a98ac9201eeb086843899f3a9fbf3eee gcrio.azureedge.net/google_containers/hyperkube-amd64:v1.12.0-alpha.0] 619581352} {[k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b k8s.gcr.io/nginx-slim-amd64:0.20] 103591055} {[k8s.gcr.io/nginx-slim-amd64@sha256:8ca6a9ecef3b2ef02f6e0c3d449235d9c53d532f420cc0a29a6a133aa88df256 k8s.gcr.io/nginx-slim-amd64:0.21] 95339966} {[gcr.io/kubernetes-e2e-test-images/hostexec-amd64@sha256:bdaecec5adfa7c79e9525c0992fdab36c2d68066f5e91eff0d1d9e8d73c654ea gcr.io/kubernetes-e2e-test-images/hostexec-amd64:1.1] 8407119} {[gcr.io/kubernetes-e2e-test-images/netexec-amd64@sha256:2edfad424a541b9e024f26368d3a5b7dcc1d7cd27a4ee8c1d8c3f81d9209ab2e gcr.io/kubernetes-e2e-test-images/netexec-amd64:1.0] 6227659} {[gcr.io/kubernetes-e2e-test-images/redis-amd64@sha256:3e01bcaf67cb9b5c9fa7f57ba92539c8962d59c9647b91e9ec5047a89e2bc49a gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0] 5850779} {[gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64@sha256:2dd4032e98a0450d95a0ac71a5e465f542a900812d8c41bc6ca635aed1a5fc91 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0] 5470001} {[gcr.io/kubernetes-e2e-test-images/nautilus-amd64@sha256:a4e859e40750d0e1a94470445bea3bc0ba4edc7363863a0be7a3714336040daa gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0] 4415165} {[gcr.io/kubernetes-e2e-test-images/entrypoint-tester-amd64@sha256:ed08ffff86b0a2016fa650ff76ea4b85fc3dfcab30ee4b7bd47d514ab765da89 gcr.io/kubernetes-e2e-test-images/entrypoint-tester-amd64:1.0] 2276578} {[gcr.io/kubernetes-e2e-test-images/mounttest-user-amd64@sha256:dda6519a95c934b46731a6b1492fed1b48ccc6d4aed4b754a46d7de8063a3e2b gcr.io/kubernetes-e2e-test-images/mounttest-user-amd64:1.0] 1450451} {[gcr.io/kubernetes-e2e-test-images/mounttest-amd64@sha256:dc4e2dcfbde16249c4662de673295d00778577bc2e2ca7013a1b85d4f47398ca gcr.io/kubernetes-e2e-test-images/mounttest-amd64:1.0] 1450451} {[busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47 busybox:latest] 1146369} {[k8s-gcrio.azureedge.net/pause-amd64@sha256:59eec8837a4d942cc19a52b8c09ea75121acc38114a2c68b98983ce9356b8610 k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s-gcrio.azureedge.net/pause-amd64:3.1 k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}&#xA;Jun 13 03:17:40.992: INFO: &#xA;Logging kubelet events for node k8s-agentpool1-31296431-1&#xA;Jun 13 03:17:41.002: INFO: &#xA;Logging pods the kubelet thinks is on node k8s-agentpool1-31296431-1&#xA;Jun 13 03:17:41.025: INFO: kube-proxy-fr77g started at 2018-06-13 02:57:26 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.025: INFO: &#x9;Container kube-proxy ready: true, restart count 0&#xA;Jun 13 03:17:41.025: INFO: netserver-1 started at 2018-06-13 03:16:55 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.025: INFO: &#x9;Container webserver ready: true, restart count 0&#xA;Jun 13 03:17:41.025: INFO: ss2-0 started at 2018-06-13 03:17:08 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.025: INFO: &#x9;Container nginx ready: true, restart count 0&#xA;Jun 13 03:17:41.025: INFO: simpletest.deployment-7557dbb5dc-7t47p started at 2018-06-13 03:17:31 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.025: INFO: &#x9;Container nginx ready: true, restart count 0&#xA;Jun 13 03:17:41.025: INFO: pod-517bfe9d-6eb8-11e8-9d88-000d3a184d46 started at 2018-06-13 03:17:35 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.025: INFO: &#x9;Container test-container ready: false, restart count 0&#xA;Jun 13 03:17:41.025: INFO: svc-latency-rc-bj5ls started at 2018-06-13 03:17:09 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.026: INFO: &#x9;Container svc-latency-rc ready: true, restart count 0&#xA;Jun 13 03:17:41.026: INFO: proxy-service-kkkkg-xlmm2 started at &lt;nil&gt; (0+0 container statuses recorded)&#xA;Jun 13 03:17:41.026: INFO: host-test-container-pod started at 2018-06-13 03:17:24 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.026: INFO: &#x9;Container hostexec ready: true, restart count 0&#xA;Jun 13 03:17:41.026: INFO: liveness-http started at 2018-06-13 03:16:08 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.026: INFO: &#x9;Container liveness ready: true, restart count 0&#xA;Jun 13 03:17:41.026: INFO: pod-525e7744-6eb8-11e8-b08b-000d3a184d46 started at 2018-06-13 03:17:37 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.026: INFO: &#x9;Container test-container ready: false, restart count 0&#xA;Jun 13 03:17:41.026: INFO: ss2-2 started at 2018-06-13 03:16:20 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.026: INFO: &#x9;Container nginx ready: true, restart count 0&#xA;Jun 13 03:17:41.026: INFO: server started at 2018-06-13 03:17:33 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.026: INFO: &#x9;Container server ready: false, restart count 0&#xA;Jun 13 03:17:41.026: INFO: liveness-exec started at 2018-06-13 03:15:41 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.026: INFO: &#x9;Container liveness ready: true, restart count 0&#xA;Jun 13 03:17:41.026: INFO: pod-service-account-49f93ea9-6eb8-11e8-b5c9-000d3a184d46-9qkvz started at &lt;nil&gt; (0+0 container statuses recorded)&#xA;Jun 13 03:17:41.026: INFO: pod-update-activedeadlineseconds-52912219-6eb8-11e8-a315-000d3a184d46 started at &lt;nil&gt; (0+0 container statuses recorded)&#xA;Jun 13 03:17:41.239: INFO: &#xA;Latency metrics for node k8s-agentpool1-31296431-1&#xA;Jun 13 03:17:41.239: INFO: {Operation:stop_container Method:docker_operations_latency_microseconds Quantile:0.99 Latency:30.485668s}&#xA;Jun 13 03:17:41.239: INFO: {Operation: Method:pod_start_latency_microseconds Quantile:0.99 Latency:13.88936s}&#xA;Jun 13 03:17:41.239: INFO: &#xA;Logging node info for node k8s-master-31296431-0&#xA;Jun 13 03:17:41.255: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:k8s-master-31296431-0,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/k8s-master-31296431-0,UID:74e2fb02-6eb5-11e8-9654-000d3a134c0e,ResourceVersion:7330,Generation:0,CreationTimestamp:2018-06-13 02:57:06 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: Standard_F2,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: eastus,failure-domain.beta.kubernetes.io/zone: 0,kubernetes.azure.com/cluster: t-xinhli-new3,kubernetes.io/hostname: k8s-master-31296431-0,kubernetes.io/role: master,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:10.244.0.0/24,DoNotUse_ExternalID:,ProviderID:azure:///subscriptions/c4528d9e-c99a-48bb-b12d-fde2176a43b8/resourceGroups/t-xinhli-new3/providers/Microsoft.Compute/virtualMachines/k8s-master-31296431-0,Unschedulable:false,Taints:[{node-role.kubernetes.io/master true NoSchedule &lt;nil&gt;}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{2 0} {&lt;nil&gt;} 2 DecimalSI},ephemeral-storage: {{31158935552 0} {&lt;nil&gt;}  BinarySI},hugepages-1Gi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},hugepages-2Mi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},memory: {{4114132992 0} {&lt;nil&gt;} 4017708Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{2 0} {&lt;nil&gt;} 2 DecimalSI},ephemeral-storage: {{28043041951 0} {&lt;nil&gt;} 28043041951 DecimalSI},hugepages-1Gi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},hugepages-2Mi: {{0 0} {&lt;nil&gt;} 0 DecimalSI},memory: {{4009275392 0} {&lt;nil&gt;} 3915308Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2018-06-13 02:59:10 +0000 UTC 2018-06-13 02:59:10 +0000 UTC RouteCreated RouteController created a route} {OutOfDisk False 2018-06-13 03:17:37 +0000 UTC 2018-06-13 02:56:57 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-06-13 03:17:37 +0000 UTC 2018-06-13 02:56:57 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-06-13 03:17:37 +0000 UTC 2018-06-13 02:56:57 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-06-13 03:17:37 +0000 UTC 2018-06-13 02:56:57 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-06-13 03:17:37 +0000 UTC 2018-06-13 02:57:36 +0000 UTC KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.240.255.5} {Hostname k8s-master-31296431-0}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:55cfce2841774bb4acf59a2b85bb2c17,SystemUUID:5E9AA3FE-6AB1-FF4E-8B54-9A53FE5E1C1C,BootID:ab62f162-195c-4fcc-87c7-9dd1fbb45e4b,KernelVersion:4.13.0-1018-azure,OSImage:Ubuntu 16.04.4 LTS,ContainerRuntimeVersion:docker://1.13.1,KubeletVersion:v1.12.0-alpha.0,KubeProxyVersion:v1.12.0-alpha.0,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcrio.azureedge.net/google_containers/hyperkube-amd64@sha256:b92fc22f40fa4bf5d72ddd6e82ffd5d5a98ac9201eeb086843899f3a9fbf3eee gcrio.azureedge.net/google_containers/hyperkube-amd64:v1.12.0-alpha.0] 619581352} {[fseldow/azure-cloud-controller-manager@sha256:8e41588ea607b1104fd0d785a17f9694410710c09419a455b91da8053985d7df fseldow/azure-cloud-controller-manager:e065e27] 168173406} {[k8s-gcrio.azureedge.net/kube-addon-manager-amd64@sha256:3519273916ba45cfc9b318448d4629819cb5fbccbb0822cce054dd8c1f68cb60 k8s-gcrio.azureedge.net/kube-addon-manager-amd64:v8.6] 78384272} {[k8s-gcrio.azureedge.net/pause-amd64@sha256:59eec8837a4d942cc19a52b8c09ea75121acc38114a2c68b98983ce9356b8610 k8s-gcrio.azureedge.net/pause-amd64:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}&#xA;Jun 13 03:17:41.255: INFO: &#xA;Logging kubelet events for node k8s-master-31296431-0&#xA;Jun 13 03:17:41.275: INFO: &#xA;Logging pods the kubelet thinks is on node k8s-master-31296431-0&#xA;Jun 13 03:17:41.407: INFO: cloud-controller-manager-k8s-master-31296431-0 started at &lt;nil&gt; (0+0 container statuses recorded)&#xA;Jun 13 03:17:41.407: INFO: kube-addon-manager-k8s-master-31296431-0 started at &lt;nil&gt; (0+0 container statuses recorded)&#xA;Jun 13 03:17:41.407: INFO: kube-apiserver-k8s-master-31296431-0 started at &lt;nil&gt; (0+0 container statuses recorded)&#xA;Jun 13 03:17:41.407: INFO: kube-controller-manager-k8s-master-31296431-0 started at &lt;nil&gt; (0+0 container statuses recorded)&#xA;Jun 13 03:17:41.407: INFO: kube-proxy-5976x started at 2018-06-13 02:57:26 +0000 UTC (0+1 container statuses recorded)&#xA;Jun 13 03:17:41.407: INFO: &#x9;Container kube-proxy ready: true, restart count 0&#xA;Jun 13 03:17:41.407: INFO: kube-scheduler-k8s-master-31296431-0 started at &lt;nil&gt; (0+0 container statuses recorded)&#xA;Jun 13 03:17:41.501: INFO: &#xA;Latency metrics for node k8s-master-31296431-0&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node to file /home/t-xinhli/new-provider/cloud-provider-azure/t-xinhli-new3/report/image-puller.txt&#xA;Jun 13 03:17:41.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-sched-pred-rsl86&#34; for this suite.&#xA;Jun 13 03:17:49.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered&#xA;Jun 13 03:17:49.796: INFO: namespace: e2e-tests-sched-pred-rsl86, resource: bindings, ignored listing per whitelist&#xA;Jun 13 03:17:50.097: INFO: namespace e2e-tests-sched-pred-rsl86 deletion completed in 8.535026886s&#xA;[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]&#xA;  /home/t-xinhli/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70&#xA;</system-out>
      </testcase>
      <testcase name="[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] [Feature:Example] [k8s.io] Spark should start spark master, driver and workers" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-network] DNS should support configurable pod resolv.conf" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-network] Services should release NodePorts on delete" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] Volume FStype [Feature:vsphere] verify fstype - default value should be ext4" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] [sig-node] Security Context [Feature:SecurityContext] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [Feature:RunAsGroup]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] PV Protection Verify &#34;immediate&#34; deletion of a PV that is not bound to a PVC" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-instrumentation] Stackdriver Monitoring should run Custom Metrics - Stackdriver Adapter for old resource model [Feature:StackdriverCustomMetrics]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-cluster-lifecycle] HA-master [Feature:HAMaster] survive addition/removal replicas multizone workers [Serial][Disruptive]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] Downward API volume should set mode on item file [NodeConformance] [Conformance]" classname="Kubernetes e2e suite" time="18.682054472"></testcase>
      <testcase name="[sig-storage] Subpath [Volume type: hostPathSymlink] should fail if subpath directory is outside the volume [Slow]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-scheduling] ResourceQuota should verify ResourceQuota with best effort scope." classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] Pod Disks schedule a pod w/ RW PD(s) mounted to 1 or more containers, write to PD, verify content, delete pod, and repeat in rapid succession [Slow] using 1 containers and 2 PDs" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] Subpath [Volume type: gcePDPVC] should fail if subpath file is outside the volume [Slow]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-network] NetworkPolicy NetworkPolicy between server and client should enforce multiple, stacked policies with overlapping podSelectors [Feature:NetworkPolicy]" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] PersistentVolumes-local  [Volume type: dir] Set fsGroup for local volume should set fsGroup for one pod" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-cli] Kubectl client [k8s.io] Simple pod should support exec" classname="Kubernetes e2e suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[sig-storage] Projected should update annotations on modification [NodeConformance] [Conformance]" classname="Kubernetes e2e suite" time="34.890134153"></testcase>
      <testcase name="[sig-api-machinery] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]" classname="Kubernetes e2e suite" time="10.348689081"></testcase>
      <testcase name="[sig-storage] Projected optional updates should be reflected in volume [NodeConformance] [Conformance]" classname="Kubernetes e2e suite" time="103.328927014"></testcase>
  </testsuite>